{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Prototype\n",
    "\n",
    "By Monday 6/30, make an attempt at formulating and \"solving\" your proposed problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Problem Formulation\n",
    "\n",
    "* Remove unneed columns, for example:\n",
    "    * duplicated\n",
    "    * categorical features that were turned into one-hot.\n",
    "    * features that identify specific rows, like ID number.\n",
    "    * make sure your target is properly encoded also.\n",
    "* Split training sample into train, validation, and test sub-samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unecessary columns\n",
    "train.drop(['Unnamed: 0', 'id'], axis = 1, inplace = True)\n",
    "test.drop(['Unnamed: 0', 'id'], axis = 1, inplace = True)\n",
    "\n",
    "# Replace satisfied = 1 | neutral or dissatisfied = 0\n",
    "train['satisfaction'].replace({'neutral or dissatisfied': 0, 'satisfied': 1},inplace = True)\n",
    "test['satisfaction'].replace({'neutral or dissatisfied': 0, 'satisfied': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Outliers (only numerical variables)\n",
    "outliers_summary = []\n",
    "numerical_columns = ['Age', 'Flight Distance','Arrival Delay in Minutes', 'Departure Delay in Minutes']\n",
    "for column in numerical_columns:\n",
    "  if column in train.columns:\n",
    "    Q1 = train[column].quantile(0.25)\n",
    "    Q3 = train[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((train[column] < lower_bound) | (train[column] > upper_bound)).sum()\n",
    "    outliers_summary.append([column, outliers])\n",
    "\n",
    "outliers_table = pd.DataFrame(outliers_summary, columns=['Feature', 'Outliers Count'])\n",
    "print(outliers_table)\n",
    "\n",
    "# Create Box-Plot to visualize outliers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "sns.boxplot(data=train, x='Age', ax=ax[0,0])\n",
    "sns.boxplot(data=train, x='Flight Distance', ax=ax[0,1])\n",
    "sns.boxplot(data=train, x='Arrival Delay in Minutes', ax=ax[1,0])\n",
    "sns.boxplot(data=train, x='Departure Delay in Minutes', ax=ax[1,1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features in both train and test\n",
    "train['Delay Difference'] = train['Arrival Delay in Minutes'] - train['Departure Delay in Minutes']\n",
    "test['Delay Difference'] = test['Arrival Delay in Minutes'] - test['Departure Delay in Minutes']\n",
    "\n",
    "# Get current column list and remove 'satisfaction' in train\n",
    "cols = train.columns.tolist()\n",
    "cols.remove('satisfaction')\n",
    "\n",
    "# Reorder with new features + satisfaction at the end in train\n",
    "new_order = cols + ['satisfaction']\n",
    "\n",
    "# Apply new order\n",
    "train = train[new_order]\n",
    "\n",
    "# Drop highly correlated features to avoid multi-collinearity (Inflight wifi service, Arrival Delay in Minutes)\n",
    "train.drop(['Inflight wifi service', 'Arrival Delay in Minutes'], axis = 1, inplace = True)\n",
    "test.drop(['Inflight wifi service', 'Arrival Delay in Minutes'], axis=1, inplace=True)\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical variables (StandardScaler)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# List of features to scale\n",
    "features_to_scale = train.drop(columns=['satisfaction']).select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Applying StandardScaler to the selected features in train\n",
    "scaled_features = scaler.fit_transform(train[features_to_scale])\n",
    "\n",
    "# Applying StandardScaler to the selected features in test\n",
    "scaled_features_test = scaler.transform(test[features_to_scale])\n",
    "\n",
    "# Create a DataFrame from the scaled features\n",
    "scaled_columns = [f'Scaled {col}' for col in features_to_scale]\n",
    "scaled_features_train = pd.DataFrame(scaled_features, columns=scaled_columns, index=train.index)\n",
    "scaled_features_test_df = pd.DataFrame(scaled_features_test, columns=scaled_columns, index=test.index)\n",
    "\n",
    "# Concatenate the scaled features with the original dataframe\n",
    "train = pd.concat([train, scaled_features_train], axis=1)\n",
    "test = pd.concat([test, scaled_features_test_df], axis=1)\n",
    "\n",
    "# Display the first few rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Train sample:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nTest sample:\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Initialize encoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit-transform on train set\n",
    "encoded_array = one_hot_encoder.fit_transform(train[categorical_cols]).toarray()\n",
    "\n",
    "# Transform test set\n",
    "encoded_test_array = one_hot_encoder.transform(test[categorical_cols]).toarray()\n",
    "\n",
    "# Create a DataFrame from the dense array\n",
    "encoded_df = pd.DataFrame(encoded_array,\n",
    "                          columns=one_hot_encoder.get_feature_names_out(categorical_cols),\n",
    "                          index=train.index)\n",
    "\n",
    "# Create DataFrame from encoded test array\n",
    "encoded_test_df = pd.DataFrame(encoded_test_array,\n",
    "                               columns=one_hot_encoder.get_feature_names_out(categorical_cols),\n",
    "                               index=test.index)\n",
    "\n",
    "# Drop original categorical columns and add encoded columns in train\n",
    "train_encoded = train.drop(columns=categorical_cols)\n",
    "train_encoded = pd.concat([train_encoded, encoded_df], axis=1)\n",
    "\n",
    "# Drop original categorical columns and add encoded columns in test\n",
    "test_encoded = test.drop(columns=categorical_cols)\n",
    "test_encoded = pd.concat([test_encoded, encoded_test_df], axis=1)\n",
    "\n",
    "print(train_encoded.head())\n",
    "print(test_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ML Algorithm\n",
    "\n",
    "* You only need one algorithm for now. You can do more if you like.\n",
    "* For now, focus on making it work, rather than best result.\n",
    "* Try to get a non-trivial result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KNN and Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain KNN and Logistic Regression with Hyperparameters Tuning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Scaled numerical features and encoded categorical features\n",
    "scaled_cols = [col for col in train_encoded.columns if col.startswith('Scaled ')]\n",
    "categorical_encoded_cols = one_hot_encoder.get_feature_names_out(categorical_cols).tolist()\n",
    "\n",
    "# Final features and target in train\n",
    "X = train_encoded[scaled_cols + categorical_encoded_cols]\n",
    "y = train_encoded['satisfaction']\n",
    "\n",
    "# Final features and target in test\n",
    "X_test_1 = test_encoded[scaled_cols + categorical_encoded_cols]\n",
    "y_test_1 = test_encoded['satisfaction']\n",
    "\n",
    "# Train-test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Hyperparameter Grids\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [200]\n",
    "}\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # Manhattan and Euclidean\n",
    "}\n",
    "\n",
    "# Initialize Models\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Grid Search\n",
    "lr_grid = GridSearchCV(lr, lr_params, cv=3, n_jobs=-1, verbose=1)\n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit Models\n",
    "lr_grid.fit(X_train, y_train)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Models and Predictions\n",
    "lr_best = lr_grid.best_estimator_\n",
    "knn_best = knn_grid.best_estimator_\n",
    "\n",
    "y_pred_lr = lr_best.predict(X_test)\n",
    "y_pred_knn = knn_best.predict(X_test)\n",
    "\n",
    "# Predict on external test set\n",
    "y_test_pred_lr = lr_best.predict(X_test_1)\n",
    "y_test_pred_knn = knn_best.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost and Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose another 2 models (Random Forest, XGBoost) with Hyperparameter Tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Rating Features\n",
    "rating_features = [\n",
    "    'Departure/Arrival time convenient',\n",
    "    'Ease of Online booking', 'Gate location', 'Food and drink',\n",
    "    'Online boarding', 'Seat comfort', 'Inflight entertainment',\n",
    "    'On-board service', 'Leg room service', 'Baggage handling',\n",
    "    'Checkin service', 'Inflight service', 'Cleanliness'\n",
    "]\n",
    "\n",
    "# Original and Encoded Categorical columns\n",
    "original_num_cols = rating_features + ['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Delay Difference']\n",
    "categorical_encoded_cols = one_hot_encoder.get_feature_names_out(categorical_cols).tolist()\n",
    "\n",
    "# Final features and target (train split)\n",
    "X = train_encoded[original_num_cols + categorical_encoded_cols]\n",
    "y = train_encoded['satisfaction']\n",
    "\n",
    "# Final features and target (external test)\n",
    "X_test_1 = test_encoded[original_num_cols + categorical_encoded_cols]\n",
    "y_test_1 = test_encoded['satisfaction']\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Hyperparameter Grids\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.6, 0.8],\n",
    "    'colsample_bytree': [0.6, 0.8]\n",
    "}\n",
    "\n",
    "# Initialize Models\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "rf_grid = GridSearchCV(rf_classifier, rf_params, cv=3, n_jobs=-1, verbose=1)\n",
    "xgb_grid = GridSearchCV(xgb_classifier, xgb_params, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit Models\n",
    "rf_grid.fit(X_train, y_train)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Models and Predictions\n",
    "rf_best = rf_grid.best_estimator_\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "\n",
    "# Predict on external test set\n",
    "y_test_pred_rf = rf_best.predict(X_test_1)\n",
    "y_test_pred_xgb = xgb_best.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance on Validation Sample\n",
    "\n",
    "* Compute the usual metric for your ML task.\n",
    "* Compute the score for the kaggle challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KNN and Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for train split\n",
    "print(\"Best Logistic Regression Hyperparameters:\", lr_grid.best_params_)\n",
    "print(\"Classification Report - Logistic Regression\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Best KNN Hyperparameters:\", knn_grid.best_params_)\n",
    "print(\"Classification Report - KNN\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for external test\n",
    "print(\"\\nClassification Report - Logistic Regression (External Test Set)\")\n",
    "print(classification_report(y_test_1, y_test_pred_lr))\n",
    "\n",
    "print(\"Classification Report - KNN (External Test Set)\")\n",
    "print(classification_report(y_test_1, y_test_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost and Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on train split set\n",
    "print(\"Best XGBoost Hyperparameters:\", xgb_grid.best_params_)\n",
    "print(\"Classification Report - XGBoost\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"Best Random Forest Hyperparameters:\", rf_grid.best_params_)\n",
    "print(\"Classification Report - Random Forest\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on external test set\n",
    "print(\"Classification Report - XGBoost (External Test Set)\")\n",
    "print(classification_report(y_test_1, y_test_pred_xgb))\n",
    "\n",
    "print(\"Classification Report - Random Forest (External Test Set)\")\n",
    "print(classification_report(y_test_1, y_test_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
